# -*- coding: utf-8 -*-
"""deepfake_predict_and_report.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AFm_GhbsrYafFIC1Vq9-rt6qIQKJlM7j
"""

!pip install lime scikit-image jinja2

from google.colab import files
files.upload()

from google.colab import files
files.upload()

import os
import io
import base64
import argparse
from datetime import datetime

import numpy as np
from PIL import Image, ImageChops
import matplotlib.pyplot as plt
import cv2
from skimage import img_as_ubyte
from skimage.color import rgb2gray
from skimage.segmentation import mark_boundaries
from skimage.filters import gaussian
from skimage.util import img_as_float
import tensorflow as tf
from tensorflow.keras.models import load_model

# LIME components
from lime import lime_image

# HTML templating
from jinja2 import Template

# ----------------------------
# Utility functions
# ----------------------------
def load_image(path, target_size=None):
    img = Image.open(path).convert("RGB")
    if target_size:
        img = img.resize(target_size, Image.BILINEAR)
    return img

def preprocess_for_model(pil_img, target_size=(224,224)):
    """Adjust to model input: resize, scale to [0,1], expand dims."""
    img = pil_img.resize(target_size, Image.BILINEAR)
    arr = np.array(img).astype("float32") / 255.0
    return np.expand_dims(arr, axis=0)

def predict_image(model, img_array):
    """Return (probability, label) assuming single-output sigmoid."""
    pred = model.predict(img_array)
    # If output shape is (1,1) or (1,), extract float
    if isinstance(pred, (list, tuple)):
        pred = pred[0]
    p = float(np.squeeze(pred))
    return p

def save_figure_to_base64(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight')
    plt.close(fig)
    buf.seek(0)
    img_b64 = base64.b64encode(buf.getvalue()).decode('utf-8')
    return img_b64

# ----------------------------
# Statistical forensic functions
# ----------------------------
def error_level_analysis(pil_img, resave_quality=90):
    """Perform ELA: resave image at lower quality and compute difference."""
    # Save original into bytes as JPEG at high quality to ensure baseline
    orig_byte_arr = io.BytesBytesIO()
    pil_img.save(orig_byte_arr, format='JPEG', quality=100)
    orig_bytes = orig_byte_arr.getvalue()

    # Re-save at lower quality
    low_byte_arr = io.BytesIO()
    pil_img.save(low_byte_arr, format='JPEG', quality=resave_quality)
    low_bytes = low_byte_arr.getvalue()

    # Load back both and compute absolute difference
    orig = Image.open(io.BytesIO(orig_bytes)).convert("RGB")
    low = Image.open(io.BytesIO(low_bytes)).convert("RGB")
    ela_img = ImageChops.difference(orig, low)

    # Amplify differences for visualization
    extrema = ela_img.getextrema()
    maxd = max([ex[1] for ex in extrema])
    scale = 1
    if maxd != 0:
        scale = 255.0 / maxd
    ela_enh = Image.eval(ela_img, lambda px: int(px * scale))
    return ela_enh

def hf_energy_ratio(pil_img, block=30):
    """High-frequency energy ratio from 2D FFT of grayscale image.
       Compute energy outside central low-frequency square."""
    gray = np.array(rgb2gray(np.array(pil_img)))
    f = np.fft.fft2(gray)
    fshift = np.fft.fftshift(f)
    power = np.abs(fshift) ** 2
    h, w = power.shape
    cx, cy = w // 2, h // 2
    half = min(h, w) // block  # central low-frequency radius
    # low-frequency square
    lf = power[cy - half:cy + half + 1, cx - half:cx + half + 1].sum()
    total = power.sum()
    hf_ratio = float((total - lf) / (total + 1e-12))
    return hf_ratio

def noise_residual_strength(pil_img, sigma=3.0):
    """Estimate noise residual by subtracting gaussian-smoothed image and taking std."""
    arr = img_as_float(np.array(pil_img))
    blurred = gaussian(arr, sigma=sigma, multichannel=True)
    residual = arr - blurred
    # compute per-channel std then mean
    if residual.ndim == 3:
        stds = residual.reshape(-1, 3).std(axis=0)
        strength = float(np.mean(stds))
    else:
        strength = float(residual.std())
    return strength

def color_channel_stats(pil_img):
    arr = np.array(pil_img).astype("float32") / 255.0
    mean_per_channel = list(np.mean(arr.reshape(-1,3), axis=0))
    std_per_channel = list(np.std(arr.reshape(-1,3), axis=0))
    return mean_per_channel, std_per_channel

# ----------------------------
# LIME explanation
# ----------------------------
def lime_explain(model, pil_img, top_labels=1, num_samples=300):
    """Run LIME on an image and return (image_with_mask_array, mask) pair base64."""
    # LIME expects function that takes list of images and returns prediction probabilities
    def predict_fn(images):
        # images are numpy arrays in range 0-255 floats -> convert to model input scaling
        imgs = np.array(images).astype("float32") / 255.0
        preds = model.predict(imgs)
        # If model returns shape (N,1), convert to (N,2) pseudo-proba [1-p, p] for Lime
        p = np.squeeze(preds)
        if p.ndim == 0:
            p = np.array([p])
        # build two-column array: [fake_prob, real_prob] or [1-p, p]
        probs = np.vstack([1 - p, p]).T
        return probs

    explainer = lime_image.LimeImageExplainer()
    img_arr = np.array(pil_img)
    explanation = explainer.explain_instance(img_arr, predict_fn, top_labels=top_labels, hide_color=0, num_samples=num_samples)
    label = explanation.top_labels[0] if len(explanation.top_labels) > 0 else 1
    temp, mask = explanation.get_image_and_mask(label, positive_only=False, num_features=10, hide_rest=False)
    # mark boundaries for better visualization
    marked = mark_boundaries(temp / 255.0, mask)
    fig = plt.figure(figsize=(6,6))
    plt.axis('off')
    plt.imshow(marked)
    img_b64 = save_figure_to_base64(fig)
    return img_b64

# ----------------------------
# Report generation (HTML)
# ----------------------------
HTML_TEMPLATE = """
<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Deepfake Prediction Report</title>
  <style>
    body { font-family: Arial, sans-serif; padding: 20px; color: #222; }
    .header { display:flex; align-items:center; justify-content:space-between; }
    .cards { display:flex; gap: 12px; margin-top:10px; }
    .card { border:1px solid #ddd; padding:12px; border-radius:6px; }
    .imgcol { display:flex; gap:12px; margin-top:12px; }
    img { max-width: 100%; height: auto; }
    table { border-collapse: collapse; margin-top:12px; }
    th, td { border:1px solid #ddd; padding:8px; }
  </style>
</head>
<body>
  <div class="header">
    <h1>Deepfake Prediction Report</h1>
    <div>Generated: {{ time }}</div>
  </div>

  <h2>Prediction</h2>
  <div class="cards">
    <div class="card">
      <strong>Model prediction:</strong> <span style="font-size:1.2em;">{{ prediction_text }}</span><br/>
      <strong>Confidence:</strong> {{ confidence:.3f }}
    </div>
    <div class="card">
      <strong>Image:</strong><br/>
      <img src="data:image/png;base64,{{ orig_img }}" alt="original" width="300"/>
    </div>
  </div>

  <h2>Interpretable Explanation (LIME)</h2>
  <p>Superpixel-based local explanation showing regions that influenced the model decision.</p>
  <div class="imgcol">
    <div class="card"><img src="data:image/png;base64,{{ lime_img }}" alt="lime" width="400"/></div>
  </div>

  <h2>Error Level Analysis (ELA)</h2>
  <p>ELA highlights regions altered by recompression; bright regions may indicate manipulation or editing.</p>
  <div class="imgcol">
    <div class="card"><img src="data:image/png;base64,{{ ela_img }}" alt="ela" width="400"/></div>
  </div>

  <h2>Statistical Forensic Cues</h2>
  <table>
    <tr><th>Statistic</th><th>Value</th><th>Interpretation (heuristic)</th></tr>
    <tr><td>High-frequency energy ratio</td><td>{{ hf_ratio:.4f }}</td>
      <td>{% if hf_ratio > hf_thresh %}Relatively high HF energy — possible GAN/processing artifacts{% else %}HF energy within ordinary range{% endif %}</td></tr>
    <tr><td>Noise residual strength</td><td>{{ noise_strength:.4f }}</td>
      <td>{% if noise_strength < noise_thresh %}Very low residual noise — may indicate synthetic smoothing or generation{% else %}Residual noise present (typical of camera images){% endif %}</td></tr>
    <tr><td>Color channel means (R,G,B)</td><td>{{ mean_r }}, {{ mean_g }}, {{ mean_b }}</td>
      <td>Color balance can indicate lighting inconsistencies if channels differ strongly.</td></tr>
    <tr><td>Color channel std (R,G,B)</td><td>{{ std_r }}, {{ std_g }}, {{ std_b }}</td>
      <td>Low channel std may indicate oversmoothing.</td></tr>
  </table>

  <h2>Conclusion</h2>
  <p><strong>Final decision:</strong> {{ prediction_text }} ({{ confidence:.3f }})</p>
  <p><strong>Notes:</strong> The decision is based on the trained classifier. The forensic cues provide additional evidence; they are heuristic indicators and should be used together with domain knowledge. LIME explains which image regions most influenced the classifier.</p>

</body>
</html>
"""

def generate_html_report(out_path, context):
    tpl = Template(HTML_TEMPLATE)
    html = tpl.render(**context)
    with open(out_path, 'w', encoding='utf-8') as f:
        f.write(html)


# ----------------------------
# Main CLI
# ----------------------------
def main(args):
    # 1. Load model
    if not os.path.exists(args.model):
        raise FileNotFoundError(f"Model file not found: {args.model}")
    model = load_model(args.model)
    # try to infer expected input size
    try:
        input_shape = model.input_shape
        # Model input shape might be (None, H, W, C)
        if isinstance(input_shape, (list, tuple)):
            _, H, W, C = input_shape
            target_size = (W, H)
        else:
            target_size = (224, 224)
    except Exception:
        target_size = (224, 224)

    # 2. Load image
    if not os.path.exists(args.image):
        raise FileNotFoundError(f"Image file not found: {args.image}")
    orig_img = load_image(args.image)  # keep full resolution copy

    # 3. Preprocess and predict
    arr = preprocess_for_model(orig_img, target_size=target_size)
    prob = predict_image(model, arr)
    # Assuming model returns probability of "real" class; adjust label names if needed
    label_text = "Real (authentic)" if prob > 0.5 else "Fake / Manipulated"

    # 4. LIME explanation (can be slow)
    print("Running LIME explanation (this may take ~30-120 seconds depending on num_samples)...")
    lime_img_b64 = lime_explain(model, orig_img, top_labels=1, num_samples=300)

    # 5. ELA image
    ela_img = error_level_analysis(orig_img, resave_quality=90)
    fig = plt.figure(figsize=(6,6))
    plt.axis('off')
    plt.imshow(ela_img)
    ela_b64 = save_figure_to_base64(fig)

    # 6. Statistical cues
    hf_ratio = hf_energy_ratio(orig_img, block=30)
    noise_strength = noise_residual_strength(orig_img, sigma=3.0)
    mean_ch, std_ch = color_channel_stats(orig_img)
    mean_r, mean_g, mean_b = mean_ch
    std_r, std_g, std_b = std_ch

    # Heuristic thresholds (tunable)
    hf_thresh = 0.5   # if more than half energy is HF -> suspicious
    noise_thresh = 0.002  # very small residual -> suspicious (synthetic smoothing)

    # 7. Original image base64
    # Save original image as PNG bytes
    buf = io.BytesIO()
    orig_img.save(buf, format='PNG')
    orig_b64 = base64.b64encode(buf.getvalue()).decode('utf-8')

    # 8. Compose report context
    context = {
        "time": datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC"),
        "prediction_text": label_text,
        "confidence": prob,
        "orig_img": orig_b64,
        "lime_img": lime_img_b64,
        "ela_img": ela_b64,
        "hf_ratio": hf_ratio,
        "noise_strength": noise_strength,
        "mean_r": f"{mean_r:.3f}",
        "mean_g": f"{mean_g:.3f}",
        "mean_b": f"{mean_b:.3f}",
        "std_r": f"{std_r:.3f}",
        "std_g": f"{std_g:.3f}",
        "std_b": f"{std_b:.3f}",
        "hf_thresh": hf_thresh,
        "noise_thresh": noise_thresh
    }

    generate_html_report(args.out, context)
    print(f"Report saved to: {args.out}")
    print(f"Model prediction: {label_text} (confidence={prob:.4f})")
    print("Done.")


if __name__ == "__main__":
    # Define the paths directly in the notebook
    model_path = "/usr/local/lib/python3.12/dist-packages/deepfake_classification_model.h5"  # Replace with your model path
    image_path = "input.jpeg"        # Replace with your image path
    output_path = "deepfake_report.html" # Replace with your desired output path

    # Create a simple object to mimic the argparse Namespace
    class Args:
        def __init__(self, model, image, out):
            self.model = model
            self.image = image
            self.out = out

    args = Args(model_path, image_path, output_path)

    # Call the main function with the defined paths
    main(args)